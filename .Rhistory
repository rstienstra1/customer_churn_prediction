data <- read.csv(".data\retail.xlsx")
data <- read_excel("./data/retail.xlsx")
library(ggplot2)
library(tidyverse)
library(readxl)
data <- read_excel("./data/retail.xlsx")
View(data)
snapshot_date <- max(data$InvoiceDate)
last_purchase <- data %>%
group_by(CustomerID) %>%
summarise(LastPurchase = max(InvoiceDate))
View(last_purchase)
churned_customers <- last_purchase %>%
mutate(DaysSinceLastPurchase = as.numeric(snapshot_date - LastPurchase, units = "days"),
Churned = DaysSinceLastPurchase > 90)
View(churned_customers)
data_churn <- data %>%
left_join(churned_customers, by = "CustomerID")
View(data_churn)
View(data)
returns_data <- data %>%
filter(Quantity < 0)
# Top customers by number of returns
returns_summary <- returns_data %>%
group_by(CustomerID) %>%
summarise(ReturnCount = n(),
TotalReturned = sum(abs(Quantity))) %>%
arrange(desc(TotalReturned))
View(returns_summary)
customer_features <- data %>%
filter(Quantity > 0) %>%  # Ignore returns for feature calc
group_by(CustomerID) %>%
summarise(
Recency = as.numeric(snapshot_date - max(InvoiceDate), units = "days"),
Frequency = n_distinct(InvoiceNo),
Monetary = sum(Quantity * UnitPrice, na.rm = TRUE),
AvgQuantity = mean(Quantity),
AvgUnitPrice = mean(UnitPrice),
UniqueItems = n_distinct(StockCode)
) %>%
left_join(churned_customers, by = "CustomerID")
View(customer_features)
ggplot(customer_features, aes(x = Frequency, fill = Churned)) +
geom_histogram(position = "dodge", bins = 30) +
labs(title = "Frequency of Purchases vs Churn")
ggplot(customer_features, aes(x = Monetary, fill = Churned)) +
geom_histogram(position = "dodge", bins = 30) +
labs(title = "Total Spend vs Churn")
ggplot(customer_features, aes(x = Frequency, fill = Churned)) +
geom_histogram(position = "dodge", bins = 3) +
labs(title = "Frequency of Purchases vs Churn")
log_model <- glm(Churned ~ Recency + Frequency + Monetary + AvgQuantity + AvgUnitPrice + UniqueItems + NumReturns,
data = customer_features,
family = "binomial")
log_model <- glm(Churned ~ Recency + Frequency + Monetary + AvgQuantity + AvgUnitPrice + UniqueItems,
data = customer_features,
family = "binomial")
# Make sure Churned is a factor
customer_features$Churned <- as.factor(customer_features$Churned)
rf_model <- randomForest(Churned ~ Recency + Frequency + Monetary + AvgQuantity + AvgUnitPrice + UniqueItems + NumReturns,
data = customer_features,
importance = TRUE)
library(randomForest)
rf_model <- randomForest(Churned ~ Recency + Frequency + Monetary + AvgQuantity + AvgUnitPrice + UniqueItems + NumReturns,
data = customer_features,
importance = TRUE)
rf_model <- randomForest(Churned ~ Recency + Frequency + Monetary + AvgQuantity + AvgUnitPrice + UniqueItems,
data = customer_features,
importance = TRUE)
# Plot feature importance
varImpPlot(rf_model)
# Plot feature importance
summary(rf_model)
library(ggplot2)
library(tidyverse)
library(readxl)
library(lubridate)
library(randomForest)
library(pROC)  # For ROC curve
# Data --------------------------------------------------------------------
retail_data <- read_excel("./data/retail.xlsx")
# Function to add churn labels to data
compute_churn_labels <- function(data, churn_days = 90) {
snapshot_date <- max(data$InvoiceDate)
last_purchase <- data %>%
group_by(CustomerID) %>%
summarise(LastPurchase = max(InvoiceDate), .groups = "drop")
churned <- last_purchase %>%
mutate(
DaysSinceLastPurchase = as.numeric(snapshot_date - LastPurchase, units = "days"),
Churned = DaysSinceLastPurchase > churn_days
)
left_join(data, churned, by = "CustomerID")
}
# Add churn labels to the full dataset
data_churn <- compute_churn_labels(retail_data)
View(data_churn)
valid_orders <- retail_data %>%
filter(!str_starts(InvoiceNo, "C") & Quantity > 0)
View(valid_orders)
library(ggplot2)
library(tidyverse)
library(readxl)
library(lubridate)
library(randomForest)
library(pROC)  # For ROC curve
# Data --------------------------------------------------------------------
retail_data <- read_excel("./data/retail.xlsx") %>%
filter(!is.na(CustomerID))
# Function to add churn labels to data
compute_churn_labels <- function(data, churn_days = 90) {
snapshot_date <- max(data$InvoiceDate)
last_purchase <- data %>%
group_by(CustomerID) %>%
summarise(LastPurchase = max(InvoiceDate), .groups = "drop")
churned <- last_purchase %>%
mutate(
DaysSinceLastPurchase = as.numeric(snapshot_date - LastPurchase, units = "days"),
Churned = DaysSinceLastPurchase > churn_days
)
left_join(data, churned, by = "CustomerID")
}
# Add churn labels to the full dataset
data_churn <- compute_churn_labels(retail_data)
valid_orders <- retail_data %>%
filter(!str_starts(InvoiceNo, "C") & Quantity > 0)
View(valid_orders)
customer_features <- valid_orders %>%
group_by(CustomerID) %>%
summarise(
Recency = as.numeric(max(data_churn$InvoiceDate) - max(InvoiceDate), units = "days"),
Frequency = n_distinct(InvoiceNo),
Monetary = sum(Quantity * UnitPrice, na.rm = TRUE),
AvgQuantity = mean(Quantity, na.rm = TRUE),
AvgUnitPrice = mean(UnitPrice, na.rm = TRUE),
UniqueItems = n_distinct(StockCode),
.groups = "drop"
) %>%
left_join(
data_churn %>%
distinct(CustomerID, DaysSinceLastPurchase, Churned),
by = "CustomerID"
)
View(customer_features)
unique(valid_orders$CustomerID)
View(valid_orders)
unique(valid_orders$Country)
returns <- retail_data %>%
filter(Quantity < 0) %>%
group_by(CustomerID) %>%
summarise(
NumReturns = n(),
ReturnedQty = sum(abs(Quantity)),
.groups = "drop"
)
customer_features <- customer_features %>%
left_join(returns, by = "CustomerID") %>%
replace_na(list(NumReturns = 0, ReturnedQty = 0))
View(customer_features)
log_model <- glm(Churned ~ Recency + Frequency + Monetary + AvgQuantity + AvgUnitPrice + UniqueItems + NumReturns + ReturnedQty,
data = customer_features,
family = "binomial")
# Make sure Churned is a factor for classification
customer_features$Churned <- as.factor(customer_features$Churned)
rf_model <- randomForest(Churned ~ Recency + Frequency + Monetary + AvgQuantity + AvgUnitPrice + UniqueItems + NumReturns + ReturnedQty,
data = customer_features,
importance = TRUE)
print(rf_model)
# Variable importance plot
varImpPlot(rf_model)
# Set a seed for reproducibility
set.seed(123)
# Set a seed for reproducibility
set.seed(123)
# Load libraries ----------------------------------------------------------
library(ggplot2)
library(tidyverse)
library(readxl)
library(lubridate)
library(randomForest)
library(pROC)  # For ROC curve
# Data --------------------------------------------------------------------
retail_data <- read_excel("./data/retail.xlsx") %>%
filter(!is.na(CustomerID))
# Wrangling & Churn Labeling ----------------------------------------------
# Function to add churn labels to data
compute_churn_labels <- function(data, churn_days = 90) {
snapshot_date <- max(data$InvoiceDate)
last_purchase <- data %>%
group_by(CustomerID) %>%
summarise(LastPurchase = max(InvoiceDate), .groups = "drop")
churned <- last_purchase %>%
mutate(
DaysSinceLastPurchase = as.numeric(snapshot_date - LastPurchase, units = "days"),
Churned = DaysSinceLastPurchase > churn_days
)
left_join(data, churned, by = "CustomerID")
}
# Add churn labels to the full dataset
data_churn <- compute_churn_labels(retail_data)
# Filter valid orders (exclude cancellations and returns) -----------------
valid_orders <- retail_data %>%
filter(!str_starts(InvoiceNo, "C") & Quantity > 0)
# Create customer-level features ------------------------------------------
customer_features <- valid_orders %>%
group_by(CustomerID) %>%
summarise(
Recency = as.numeric(max(data_churn$InvoiceDate) - max(InvoiceDate), units = "days"),
Frequency = n_distinct(InvoiceNo),
Monetary = sum(Quantity * UnitPrice, na.rm = TRUE),
AvgQuantity = mean(Quantity, na.rm = TRUE),
AvgUnitPrice = mean(UnitPrice, na.rm = TRUE),
UniqueItems = n_distinct(StockCode),
.groups = "drop"
) %>%
left_join(
data_churn %>%
distinct(CustomerID, DaysSinceLastPurchase, Churned),
by = "CustomerID"
)
# Add return features ------------------------------------------------------
returns <- retail_data %>%
filter(Quantity < 0) %>%
group_by(CustomerID) %>%
summarise(
NumReturns = n(),
ReturnedQty = sum(abs(Quantity)),
.groups = "drop"
)
customer_features <- customer_features %>%
left_join(returns, by = "CustomerID") %>%
replace_na(list(NumReturns = 0, ReturnedQty = 0))
# Random Forest Model -----------------------------------------------------
# Build the random forest model
rf_model <- randomForest(
Churned ~ Recency + Frequency + Monetary + AvgQuantity + AvgUnitPrice + UniqueItems + NumReturns + ReturnedQty,
data = customer_features,
importance = TRUE,
ntree = 500,       # Increase number of trees for stability
mtry = 3,          # Try tuning this (sqrt of number of predictors is a good start)
na.action = na.roughfix # Handle any remaining NAs by imputation
)
# Print summary
print(rf_model)
# Make sure Churned is a factor (classification)
customer_features$Churned <- as.factor(customer_features$Churned)
# Build the random forest model
rf_model <- randomForest(
Churned ~ Recency + Frequency + Monetary + AvgQuantity + AvgUnitPrice + UniqueItems + NumReturns + ReturnedQty,
data = customer_features,
importance = TRUE,
ntree = 500,       # Increase number of trees for stability
mtry = 3,          # Try tuning this (sqrt of number of predictors is a good start)
na.action = na.roughfix # Handle any remaining NAs by imputation
)
# Print summary
print(rf_model)
# Plot error rate across trees
plot(rf_model)
# Variable importance plot
varImpPlot(rf_model, type = 2, main = "Random Forest Variable Importance")
View(valid_orders)
split <- sample(1:nrow(customer_features), 0.7 * nrow(customer_features))
train <- customer_features[split, ]
test <- customer_features[-split, ]
View(train)
# Set a seed for reproducibility
set.seed(123)
# Load libraries ----------------------------------------------------------
library(ggplot2)
library(tidyverse)
library(readxl)
library(lubridate)
library(randomForest)
library(pROC)  # For ROC curve
# Data --------------------------------------------------------------------
retail_data <- read_excel("./data/retail.xlsx") %>%
filter(!is.na(CustomerID))
# Wrangling & Churn Labeling ----------------------------------------------
# Function to add churn labels to data
compute_churn_labels <- function(data, churn_days = 90) {
snapshot_date <- max(data$InvoiceDate)
last_purchase <- data %>%
group_by(CustomerID) %>%
summarise(LastPurchase = max(InvoiceDate), .groups = "drop")
churned <- last_purchase %>%
mutate(
DaysSinceLastPurchase = as.numeric(snapshot_date - LastPurchase, units = "days"),
Churned = DaysSinceLastPurchase > churn_days
)
left_join(data, churned, by = "CustomerID")
}
# Add churn labels to the full dataset
data_churn <- compute_churn_labels(retail_data)
# Filter valid orders (exclude cancellations and returns) -----------------
valid_orders <- retail_data %>%
filter(!str_starts(InvoiceNo, "C") & Quantity > 0)
# Create customer-level features ------------------------------------------
customer_features <- valid_orders %>%
group_by(CustomerID) %>%
summarise(
Recency = as.numeric(max(data_churn$InvoiceDate) - max(InvoiceDate), units = "days"),
Frequency = n_distinct(InvoiceNo),
Monetary = sum(Quantity * UnitPrice, na.rm = TRUE),
AvgQuantity = mean(Quantity, na.rm = TRUE),
AvgUnitPrice = mean(UnitPrice, na.rm = TRUE),
UniqueItems = n_distinct(StockCode),
.groups = "drop"
) %>%
left_join(
data_churn %>%
distinct(CustomerID, DaysSinceLastPurchase, Churned),
by = "CustomerID"
)
# Add return features ------------------------------------------------------
returns <- retail_data %>%
filter(Quantity < 0) %>%
group_by(CustomerID) %>%
summarise(
NumReturns = n(),
ReturnedQty = sum(abs(Quantity)),
.groups = "drop"
)
customer_features <- customer_features %>%
left_join(returns, by = "CustomerID") %>%
replace_na(list(NumReturns = 0, ReturnedQty = 0))
# Train / Test Split ------------------------------------------------------
split <- sample(1:nrow(customer_features), 0.7 * nrow(customer_features))
train <- customer_features[split, ]
test <- customer_features[-split, ]
# Make sure Churned is a factor for classification
train$Churned <- as.factor(train$Churned)
test$Churned <- as.factor(test$Churned)
# Build model using all engineered features
rf_model <- randomForest(
Churned ~ Recency + Frequency + Monetary + AvgQuantity + AvgUnitPrice + UniqueItems + NumReturns + ReturnedQty,
data = train,
importance = TRUE,
ntree = 500,
mtry = 3,
na.action = na.roughfix
)
# Print model summary
print(rf_model)
# Variable importance plot
varImpPlot(rf_model, type = 2, main = "Random Forest Variable Importance")
# Predict on test set
rf_pred <- predict(rf_model, newdata = test, type = "response")
# Confusion matrix
conf_matrix <- table(Predicted = rf_pred, Actual = test$Churned)
print(conf_matrix)
# Need probabilities for ROC
rf_probs <- predict(rf_model, newdata = test, type = "prob")[, "TRUE"]
# ROC and AUC
roc_obj <- roc(test$Churned, rf_probs)
auc_value <- auc(roc_obj)
# Plot ROC curve
plot(roc_obj, main = paste("ROC Curve (AUC =", round(auc_value, 3), ")"))
# Print AUC
print(paste("AUC:", round(auc_value, 3)))
# Build model using all engineered features
rf_model <- randomForest(
Churned ~ Frequency + Monetary + AvgQuantity + AvgUnitPrice + UniqueItems + NumReturns + ReturnedQty,
data = train,
importance = TRUE,
ntree = 500,
mtry = 3,
na.action = na.roughfix
)
# Print model summary
print(rf_model)
# Variable importance plot
varImpPlot(rf_model, type = 2, main = "Random Forest Variable Importance")
# Predict on test set
rf_pred <- predict(rf_model, newdata = test, type = "response")
# Confusion matrix
conf_matrix <- table(Predicted = rf_pred, Actual = test$Churned)
print(conf_matrix)
# Need probabilities for ROC
rf_probs <- predict(rf_model, newdata = test, type = "prob")[, "TRUE"]
roc_obj <- roc(test$Churned, rf_probs)
auc_value <- auc(roc_obj)
# Plot ROC curve
plot(roc_obj, main = paste("ROC Curve (AUC =", round(auc_value, 3), ")"))
# Print AUC
print(paste("AUC:", round(auc_value, 3)))
# Variable importance plot
varImpPlot(rf_model, type = 2, main = "Random Forest Variable Importance")
# Print model summary
print(rf_model)
importance_values <- importance(rf_model)
print(importance_values)
# Plot importance based on MeanDecreaseGini
varImpPlot(rf_model, type = 2, main = "Random Forest Variable Importance")
